{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjetoBCFinal.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6xB6kSkfLXHXWWe4/W3yb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricardosaj/ProjetoFinalBootcampAluraDataScience/blob/main/ProjetoBCFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Projeto para prever necessidade de leito de UTI \n"
      ],
      "metadata": {
        "id": "HfxF1BVmtJVd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CZiZ2DxHtGgk",
        "outputId": "5a450392-4793-40c2-fb36-b708ffa02048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neuralprophet\n",
            "  Downloading neuralprophet-0.3.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting dataclasses>=0.6\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from neuralprophet) (3.2.2)\n",
            "Collecting holidays>=0.11.3.1\n",
            "  Downloading holidays-0.13-py3-none-any.whl (172 kB)\n",
            "\u001b[K     |████████████████████████████████| 172 kB 39.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: convertdate>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from neuralprophet) (2.4.0)\n",
            "Requirement already satisfied: ipywidgets>=7.5.1 in /usr/local/lib/python3.7/dist-packages (from neuralprophet) (7.6.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from neuralprophet) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from neuralprophet) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.50.2 in /usr/local/lib/python3.7/dist-packages (from neuralprophet) (4.62.3)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from neuralprophet) (1.3.5)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.7/dist-packages (from neuralprophet) (0.0.9)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from neuralprophet) (1.10.0+cu111)\n",
            "Collecting torch-lr-finder>=0.2.1\n",
            "  Downloading torch_lr_finder-0.2.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.1.2->neuralprophet) (0.5.11)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays>=0.11.3.1->neuralprophet) (0.2.1)\n",
            "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays>=0.11.3.1->neuralprophet) (2.2.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->neuralprophet) (1.0.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->neuralprophet) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->neuralprophet) (3.5.2)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->neuralprophet) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->neuralprophet) (5.1.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->neuralprophet) (5.1.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.1->neuralprophet) (4.10.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->neuralprophet) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5.1->neuralprophet) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->neuralprophet) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->neuralprophet) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->neuralprophet) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->neuralprophet) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->neuralprophet) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->neuralprophet) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->neuralprophet) (4.8.0)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.7/dist-packages (from LunarCalendar>=0.0.9->neuralprophet) (4.1.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from LunarCalendar>=0.0.9->neuralprophet) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->neuralprophet) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->neuralprophet) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->neuralprophet) (1.3.2)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->neuralprophet) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.1->neuralprophet) (4.9.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->neuralprophet) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->neuralprophet) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->neuralprophet) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->neuralprophet) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->neuralprophet) (4.11.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5.1->neuralprophet) (3.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.5.1->neuralprophet) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.5.1->neuralprophet) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torch-lr-finder>=0.2.1->neuralprophet) (21.3)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->neuralprophet) (5.3.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->neuralprophet) (1.8.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->neuralprophet) (5.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->neuralprophet) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->neuralprophet) (0.13.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5.1->neuralprophet) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->neuralprophet) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->neuralprophet) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->neuralprophet) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->neuralprophet) (4.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->neuralprophet) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->neuralprophet) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->neuralprophet) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->neuralprophet) (0.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.5.1->neuralprophet) (0.5.1)\n",
            "Installing collected packages: torch-lr-finder, holidays, dataclasses, neuralprophet\n",
            "  Attempting uninstall: holidays\n",
            "    Found existing installation: holidays 0.10.5.2\n",
            "    Uninstalling holidays-0.10.5.2:\n",
            "      Successfully uninstalled holidays-0.10.5.2\n",
            "Successfully installed dataclasses-0.6 holidays-0.13 neuralprophet-0.3.0 torch-lr-finder-0.2.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dataclasses"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install neuralprophet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from neuralprophet import NeuralProphet\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, Normalizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import roc_auc_score, classification_report, ConfusionMatrixDisplay, f1_score\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from joblib import dump, load"
      ],
      "metadata": {
        "id": "Lj_nE9WytJ5B"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl==3.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "ym09x97xFuou",
        "outputId": "8b997035-9217-44cf-8288-47fadb492ae2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openpyxl==3.0.0\n",
            "  Downloading openpyxl-3.0.0.tar.gz (172 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 40 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 51 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 61 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 71 kB 28.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 81 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 102 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 112 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 122 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 133 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 143 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 153 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 163 kB 28.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 172 kB 28.3 MB/s \n",
            "\u001b[?25hCollecting jdcal\n",
            "  Downloading jdcal-1.4.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: et_xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl==3.0.0) (1.1.0)\n",
            "Building wheels for collected packages: openpyxl\n",
            "  Building wheel for openpyxl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openpyxl: filename=openpyxl-3.0.0-py2.py3-none-any.whl size=241207 sha256=01a3aac208690199b78708728a5165415252aecc2e16b6211cccd88686e66bfe\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/64/ff/ce98f6e1d2701ae8e216c875da62feed2839ac8a3cae0ab8af\n",
            "Successfully built openpyxl\n",
            "Installing collected packages: jdcal, openpyxl\n",
            "  Attempting uninstall: openpyxl\n",
            "    Found existing installation: openpyxl 3.0.9\n",
            "    Uninstalling openpyxl-3.0.9:\n",
            "      Successfully uninstalled openpyxl-3.0.9\n",
            "Successfully installed jdcal-1.4.1 openpyxl-3.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openpyxl"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados = pd.read_excel(\"https://github.com/ricardosaj/ProjetoFinalBootcampAluraDataScience/blob/main/Kaggle_Sirio_Libanes_ICU_Prediction.xlsx?raw=true\")\n",
        "dados.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "S4Iblwp2taKd",
        "outputId": "082bef9c-a82a-4b44-f309-5c27ceb941bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3be2f244-99f4-43f1-920a-668758043769\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PATIENT_VISIT_IDENTIFIER</th>\n",
              "      <th>AGE_ABOVE65</th>\n",
              "      <th>AGE_PERCENTIL</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>DISEASE GROUPING 1</th>\n",
              "      <th>DISEASE GROUPING 2</th>\n",
              "      <th>DISEASE GROUPING 3</th>\n",
              "      <th>DISEASE GROUPING 4</th>\n",
              "      <th>DISEASE GROUPING 5</th>\n",
              "      <th>DISEASE GROUPING 6</th>\n",
              "      <th>HTN</th>\n",
              "      <th>IMMUNOCOMPROMISED</th>\n",
              "      <th>OTHER</th>\n",
              "      <th>ALBUMIN_MEDIAN</th>\n",
              "      <th>ALBUMIN_MEAN</th>\n",
              "      <th>ALBUMIN_MIN</th>\n",
              "      <th>ALBUMIN_MAX</th>\n",
              "      <th>ALBUMIN_DIFF</th>\n",
              "      <th>BE_ARTERIAL_MEDIAN</th>\n",
              "      <th>BE_ARTERIAL_MEAN</th>\n",
              "      <th>BE_ARTERIAL_MIN</th>\n",
              "      <th>BE_ARTERIAL_MAX</th>\n",
              "      <th>BE_ARTERIAL_DIFF</th>\n",
              "      <th>BE_VENOUS_MEDIAN</th>\n",
              "      <th>BE_VENOUS_MEAN</th>\n",
              "      <th>BE_VENOUS_MIN</th>\n",
              "      <th>BE_VENOUS_MAX</th>\n",
              "      <th>BE_VENOUS_DIFF</th>\n",
              "      <th>BIC_ARTERIAL_MEDIAN</th>\n",
              "      <th>BIC_ARTERIAL_MEAN</th>\n",
              "      <th>BIC_ARTERIAL_MIN</th>\n",
              "      <th>BIC_ARTERIAL_MAX</th>\n",
              "      <th>BIC_ARTERIAL_DIFF</th>\n",
              "      <th>BIC_VENOUS_MEDIAN</th>\n",
              "      <th>BIC_VENOUS_MEAN</th>\n",
              "      <th>BIC_VENOUS_MIN</th>\n",
              "      <th>BIC_VENOUS_MAX</th>\n",
              "      <th>BIC_VENOUS_DIFF</th>\n",
              "      <th>BILLIRUBIN_MEDIAN</th>\n",
              "      <th>BILLIRUBIN_MEAN</th>\n",
              "      <th>...</th>\n",
              "      <th>DIMER_MAX</th>\n",
              "      <th>DIMER_DIFF</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MEAN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MEAN</th>\n",
              "      <th>HEART_RATE_MEAN</th>\n",
              "      <th>RESPIRATORY_RATE_MEAN</th>\n",
              "      <th>TEMPERATURE_MEAN</th>\n",
              "      <th>OXYGEN_SATURATION_MEAN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MEDIAN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MEDIAN</th>\n",
              "      <th>HEART_RATE_MEDIAN</th>\n",
              "      <th>RESPIRATORY_RATE_MEDIAN</th>\n",
              "      <th>TEMPERATURE_MEDIAN</th>\n",
              "      <th>OXYGEN_SATURATION_MEDIAN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MIN</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MIN</th>\n",
              "      <th>HEART_RATE_MIN</th>\n",
              "      <th>RESPIRATORY_RATE_MIN</th>\n",
              "      <th>TEMPERATURE_MIN</th>\n",
              "      <th>OXYGEN_SATURATION_MIN</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_MAX</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_MAX</th>\n",
              "      <th>HEART_RATE_MAX</th>\n",
              "      <th>RESPIRATORY_RATE_MAX</th>\n",
              "      <th>TEMPERATURE_MAX</th>\n",
              "      <th>OXYGEN_SATURATION_MAX</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_DIFF</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_DIFF</th>\n",
              "      <th>HEART_RATE_DIFF</th>\n",
              "      <th>RESPIRATORY_RATE_DIFF</th>\n",
              "      <th>TEMPERATURE_DIFF</th>\n",
              "      <th>OXYGEN_SATURATION_DIFF</th>\n",
              "      <th>BLOODPRESSURE_DIASTOLIC_DIFF_REL</th>\n",
              "      <th>BLOODPRESSURE_SISTOLIC_DIFF_REL</th>\n",
              "      <th>HEART_RATE_DIFF_REL</th>\n",
              "      <th>RESPIRATORY_RATE_DIFF_REL</th>\n",
              "      <th>TEMPERATURE_DIFF_REL</th>\n",
              "      <th>OXYGEN_SATURATION_DIFF_REL</th>\n",
              "      <th>WINDOW</th>\n",
              "      <th>ICU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.283019</td>\n",
              "      <td>-0.593220</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.086420</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.283019</td>\n",
              "      <td>-0.586207</td>\n",
              "      <td>-0.285714</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.237113</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.162393</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.208791</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>-0.247863</td>\n",
              "      <td>-0.459459</td>\n",
              "      <td>-0.432836</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>-0.420290</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0-2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.132075</td>\n",
              "      <td>-0.593220</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.230769</td>\n",
              "      <td>-0.132075</td>\n",
              "      <td>-0.586207</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.443299</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>-0.025641</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.838384</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>-0.459459</td>\n",
              "      <td>-0.313433</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>0.246377</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>2-4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>-0.938950</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.994912</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4-6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.318681</td>\n",
              "      <td>0.898990</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.275362</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>6-12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>60th</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-0.871658</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-0.863874</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-0.317073</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-0.414634</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.979069</td>\n",
              "      <td>-0.979069</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.996762</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.243021</td>\n",
              "      <td>-0.338537</td>\n",
              "      <td>-0.213031</td>\n",
              "      <td>-0.317859</td>\n",
              "      <td>0.033779</td>\n",
              "      <td>0.665932</td>\n",
              "      <td>-0.283951</td>\n",
              "      <td>-0.376923</td>\n",
              "      <td>-0.188679</td>\n",
              "      <td>-0.379310</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>-0.340206</td>\n",
              "      <td>-0.4875</td>\n",
              "      <td>-0.572650</td>\n",
              "      <td>-0.857143</td>\n",
              "      <td>0.098901</td>\n",
              "      <td>0.797980</td>\n",
              "      <td>-0.076923</td>\n",
              "      <td>0.286486</td>\n",
              "      <td>0.298507</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.362319</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>-0.33913</td>\n",
              "      <td>0.325153</td>\n",
              "      <td>0.114504</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>-0.238095</td>\n",
              "      <td>-0.818182</td>\n",
              "      <td>-0.389967</td>\n",
              "      <td>0.407558</td>\n",
              "      <td>-0.230462</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>-0.242282</td>\n",
              "      <td>-0.814433</td>\n",
              "      <td>ABOVE_12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 231 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3be2f244-99f4-43f1-920a-668758043769')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3be2f244-99f4-43f1-920a-668758043769 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3be2f244-99f4-43f1-920a-668758043769');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   PATIENT_VISIT_IDENTIFIER  AGE_ABOVE65  ...    WINDOW  ICU\n",
              "0                         0            1  ...       0-2    0\n",
              "1                         0            1  ...       2-4    0\n",
              "2                         0            1  ...       4-6    0\n",
              "3                         0            1  ...      6-12    0\n",
              "4                         0            1  ...  ABOVE_12    1\n",
              "\n",
              "[5 rows x 231 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados.PATIENT_VISIT_IDENTIFIER.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbJQnBPTui5B",
        "outputId": "41906ba2-3909-46e5-9bee-05f6379c6c7a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
              "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
              "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
              "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
              "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
              "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
              "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
              "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
              "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
              "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
              "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
              "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
              "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
              "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
              "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
              "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
              "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
              "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
              "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
              "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
              "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
              "       377, 378, 379, 380, 381, 382, 383, 384])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pymgLkZ1Egxq",
        "outputId": "5c7441c8-d1dd-4be3-cc4e-c1023b576415"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['PATIENT_VISIT_IDENTIFIER', 'AGE_ABOVE65', 'AGE_PERCENTIL', 'GENDER',\n",
              "       'DISEASE GROUPING 1', 'DISEASE GROUPING 2', 'DISEASE GROUPING 3',\n",
              "       'DISEASE GROUPING 4', 'DISEASE GROUPING 5', 'DISEASE GROUPING 6',\n",
              "       ...\n",
              "       'TEMPERATURE_DIFF', 'OXYGEN_SATURATION_DIFF',\n",
              "       'BLOODPRESSURE_DIASTOLIC_DIFF_REL', 'BLOODPRESSURE_SISTOLIC_DIFF_REL',\n",
              "       'HEART_RATE_DIFF_REL', 'RESPIRATORY_RATE_DIFF_REL',\n",
              "       'TEMPERATURE_DIFF_REL', 'OXYGEN_SATURATION_DIFF_REL', 'WINDOW', 'ICU'],\n",
              "      dtype='object', length=231)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FYAoGXyEiyy",
        "outputId": "5d2d013b-239e-4b57-aefe-513c4c0d0928"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PATIENT_VISIT_IDENTIFIER        int64\n",
              "AGE_ABOVE65                     int64\n",
              "AGE_PERCENTIL                  object\n",
              "GENDER                          int64\n",
              "DISEASE GROUPING 1            float64\n",
              "                               ...   \n",
              "RESPIRATORY_RATE_DIFF_REL     float64\n",
              "TEMPERATURE_DIFF_REL          float64\n",
              "OXYGEN_SATURATION_DIFF_REL    float64\n",
              "WINDOW                         object\n",
              "ICU                             int64\n",
              "Length: 231, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTratamento da Base com Label Encoder\")\n",
        "\n",
        "pacientes_UTI = dados[['PATIENT_VISIT_IDENTIFIER','ICU']].query('ICU == 1').groupby('PATIENT_VISIT_IDENTIFIER').min()\n",
        "dados_tratados = dados.query('ICU != 1').drop('ICU', axis=1)\n",
        "dados_tratados = dados_tratados.join(pacientes_UTI, on='PATIENT_VISIT_IDENTIFIER', how='left')\n",
        "dados_tratados['ICU'] = dados_tratados['ICU'].fillna(0) \n",
        "print(\"\\nRemovemos as linhas com ICU(UTI) igual a 1 e remarcamos a coluna com base no PATIENT_VISIT_IDENTIFIER que chegou na UTI\")\n",
        "print(f\"Distribuição de ICU na base tratada (%)\\n{dados_tratados['ICU'].value_counts(normalize=True)*100}\")\n",
        "\n",
        "features_continuas_colunas = dados_tratados.iloc[:, 13:-2].columns\n",
        "features_continuas = dados_tratados.groupby(\"PATIENT_VISIT_IDENTIFIER\",as_index=False)[features_continuas_colunas].fillna(method='bfill').fillna(method='ffill')\n",
        "features_categoricas = dados_tratados.iloc[:, :13]\n",
        "saida = dados_tratados.iloc[:, -2:]\n",
        "dados_tratados = pd.concat([features_categoricas, features_continuas, saida], ignore_index=True,axis=1)\n",
        "dados_tratados.columns = dados.columns\n",
        "print(\"\\nAjustamos os valores continuos que estavam com Nam para o valor anterior ou posterior\")\n",
        "\n",
        "descricao = dados_tratados.describe().T\n",
        "colunas_sem_variacao = descricao[descricao['min'] == descricao['max']].index\n",
        "if len(colunas_sem_variacao) !=0:\n",
        "  dados_tratados.drop(colunas_sem_variacao, axis=1)\n",
        "  print(\"\\nRemovemos as colunas que os valores são iguais para todas as linhas\")\n",
        "\n",
        "linhas_com_nam = dados_tratados.describe(include='all').loc['count'].max()-dados_tratados.describe(include='all').loc['count'].min()\n",
        "if linhas_com_nam !=0:\n",
        "  if linhas_com_nam <= len(dados_tratados)*.1:\n",
        "    dados_tratados.dropna(inplace=True)\n",
        "    print(f\"\\nAs linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_tratados):.2%} do total) foram eliminadas\")\n",
        "  else:\n",
        "    print(f\"\\nTemos linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_tratados):.2%} do total) precisam ser tratadas\")\n",
        "\n",
        "dados_tratados.reset_index(drop=True, inplace=True)\n",
        "print(f\"\\nO index foi resetado: {dados_tratados.index}\")\n",
        "\n",
        "colunas_categoricas = list(set(dados_tratados.columns)-set(dados_tratados.describe().columns)-{'WINDOW'})\n",
        "if len(colunas_categoricas) ==1:\n",
        "  dados_LE = dados_tratados.copy()\n",
        "  LE = LabelEncoder()\n",
        "  dados_LE[colunas_categoricas] = pd.DataFrame(LE.fit_transform(np.ravel(dados_tratados[colunas_categoricas])))\n",
        "  print(f\"\\nColuna com objeto categórico ({colunas_categoricas[0]}) foi transformada em numérica no DataFrame dados_LE.\\nFormato: {dados_LE.shape}\")\n",
        "else:\n",
        "  print(f\"\\nColunas com objetos categóricos precisam ser tratados: {', '.join(colunas_categoricas)}\")\n",
        "\n",
        "print(f\"\\nFormato final do DataFrame dados_tratados: {dados_tratados.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9EidqtzEtN6",
        "outputId": "4d241321-2692-4945-8f53-caf5d550b9c9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tratamento da Base com Label Encoder\n",
            "\n",
            "Removemos as linhas com ICU(UTI) igual a 1 e remarcamos a coluna com base no PATIENT_VISIT_IDENTIFIER que chegou na UTI\n",
            "Distribuição de ICU na base tratada (%)\n",
            "0.0    67.375887\n",
            "1.0    32.624113\n",
            "Name: ICU, dtype: float64\n",
            "\n",
            "Ajustamos os valores continuos que estavam com Nam para o valor anterior ou posterior\n",
            "\n",
            "Removemos as colunas que os valores são iguais para todas as linhas\n",
            "\n",
            "As linhas ainda com Nam (5.0 linhas, 0.36% do total) foram eliminadas\n",
            "\n",
            "O index foi resetado: RangeIndex(start=0, stop=1405, step=1)\n",
            "\n",
            "Coluna com objeto categórico (AGE_PERCENTIL) foi transformada em numérica no DataFrame dados_LE.\n",
            "Formato: (1405, 231)\n",
            "\n",
            "Formato final do DataFrame dados_tratados: (1405, 231)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adiciona_janela(dados_anterior, dados_janela, colunas=features_continuas_colunas):\n",
        "  \"\"\"\n",
        "  ________________________________________________________________________________________________________________\n",
        "  ENTRADAS\n",
        "  --------\n",
        "  dados_anterior: DataFrame\n",
        "      dados da janela atual que está sendo observada. Por exemplo o filtro WINDOW == '0-2'\n",
        "\n",
        "  dados_janela: DataFrame\n",
        "      dados da janela que será adcionada. Seguindo o exemplo o filtro WINDOW == '2-4'\n",
        "\n",
        "  colunas: list\n",
        "      lista de colunas que devem ser adiciondos, não deveríamos adicionar novamente os dados categóricos por \n",
        "      exemplo. Por isso, por padrão são utilizadas as features continuas\n",
        "  ________________________________________________________________________________________________________________\n",
        "  SAIDAS\n",
        "  ------\n",
        "  DataFrame\n",
        "      Nova base de dados partindo do dados_janela e adcionando as colunas seleciondas da base dados_anterior, \n",
        "      também adicionando a variação dessas colunas contra a janela anterior e removendo o que não for útil\n",
        "  \"\"\"\n",
        "  d1 = dados_janela.set_index('PATIENT_VISIT_IDENTIFIER')\n",
        "  d2 = dados_anterior.set_index('PATIENT_VISIT_IDENTIFIER')\n",
        "  sufixo = ' ' + str(dados_anterior.loc[0,\"WINDOW\"])\n",
        "  dados_novo = d1.join(d2[colunas], how='left', rsuffix=sufixo).reset_index()\n",
        "\n",
        "  for _ in colunas:\n",
        "    coluna = 'var ' + _ + sufixo\n",
        "    coluna_ = _ + sufixo\n",
        "    dados_novo[coluna] = dados_novo[_] - dados_novo[coluna_]\n",
        "\n",
        "  descricao = dados_novo.describe().T\n",
        "  colunas_sem_variacao = descricao[descricao['min'] == descricao['max']].index\n",
        "  if len(colunas_sem_variacao) !=0:\n",
        "    dados_novo.drop(colunas_sem_variacao, axis=1)\n",
        "    print(\"\\nRemovemos as colunas que os valores são iguais para todas as linhas\")\n",
        "\n",
        "  linhas_com_nam = dados_novo.describe(include='all').loc['count'].max()-dados_novo.describe(include='all').loc['count'].min()\n",
        "  if linhas_com_nam !=0:\n",
        "    if linhas_com_nam <= len(dados_novo)*.1:\n",
        "      dados_novo.dropna(inplace=True)\n",
        "      print(f\"\\nAs linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_novo):.2%} do total) foram eliminadas\")\n",
        "    else:\n",
        "      print(f\"\\nTemos linhas ainda com Nam ({linhas_com_nam} linhas, {linhas_com_nam/len(dados_novo):.2%} do total) precisam ser tratadas\")\n",
        "  print(f'\\nBase nova de tamanho: {dados_novo.shape}')\n",
        "  return dados_novo"
      ],
      "metadata": {
        "id": "M5kXoiIEGlCC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class remove_corr(BaseEstimator, TransformerMixin):\n",
        "  \"\"\"\n",
        "  ________________________________________________________________________________________________________________\n",
        "  Seleciona os dados com base na correlação deles entre si (dentro do X) e com a variável objetivo (y)\n",
        "  ________________________________________________________________________________________________________________\n",
        "  PARAMETROS\n",
        "  ----------\n",
        "  corr_maxima: float\n",
        "      define o máximo valor permitido para as correlações entre as variávies de X, acima disso as variáveris X\n",
        "      serão desconsideradas (mantendo apenas uma entre as duas que tem alta correlação entre si)\n",
        "\n",
        "  corr_minima: float\n",
        "      define o valor minimo para a correlação entre o y e as variaveis de X, abaixo disso as variaves de X \n",
        "      serão eliminadas\n",
        "  ________________________________________________________________________________________________________________\n",
        "  ATRIBUTOS\n",
        "  ---------\n",
        "  excluir: list\n",
        "      Lista das colunas/variáveris a serem excluidas do X, criado pelo método fit()\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__( self, corr_maxima = 0.95, corr_minima=0.05):\n",
        "    self.corr_maxima = corr_maxima\n",
        "    self.corr_minima = corr_minima\n",
        "\n",
        "  def fit( self, X, y):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    faz o fit do modelo, salvando uma lista de colunas/variáveris a serem excluidas do X\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADAS\n",
        "    ----------\n",
        "    X: DataFrame\n",
        "        a base das variáveis utilizadas para tentar definir o y\n",
        "\n",
        "    y: Series\n",
        "        a variável objetivo que buscamos prever\n",
        "    ________________________________________________________________________________________________________________\n",
        "    SAIDA\n",
        "    -----\n",
        "    objeto da classe remove_corr\n",
        "        modelo de seleção já configurado aguardando a utilização do método transform()\n",
        "        \n",
        "    \"\"\"\n",
        "    corr = X.corr().abs()\n",
        "    corr_diagonal = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n",
        "    self.excluir = [coluna for coluna in corr_diagonal.columns if any(corr_diagonal[coluna] > self.corr_maxima)]\n",
        "    X_ = X.drop(self.excluir, axis=1)\n",
        "    X_ = X_.join(y, how='left')\n",
        "    X_corr = X_.corr().abs()\n",
        "    self.excluir.extend(list(X_corr.query('ICU < @self.corr_minima')['ICU'].index))\n",
        "\n",
        "    return self \n",
        "    \n",
        "  def transform(self, X, y = None):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    remove as colunas/variáveis definidas pelo método fit() do DataFrame X passado\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADAS\n",
        "    ----------\n",
        "    X: DataFrame\n",
        "        a base das variáveis utilizadas para tentar encontrar definir o y que será transformada\n",
        "\n",
        "    y: Series\n",
        "        a variável objetivo que buscamos prever. \n",
        "        Não será utilizada e não precisa ser passada.\n",
        "    ________________________________________________________________________________________________________________\n",
        "    SAIDA\n",
        "    -----\n",
        "    DataFrame\n",
        "        novo DataFrame do X após a exclusão das colunas/variáveis definidas no fit()\n",
        "        \n",
        "    \"\"\"\n",
        "    X = X.drop(self.excluir, axis=1)\n",
        "    return X"
      ],
      "metadata": {
        "id": "e3CdDqDgHSl2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class seleciona_modelo():\n",
        "  \"\"\"\n",
        "  ________________________________________________________________________________________________________________\n",
        "  A partir de um modelo de classificação definido, está classe permite você testar diversas opções de pipelines\n",
        "  e configurações do modelo escolhido, com o objetivo de encontrar o que possuí maior precisão para definir o y.\n",
        "\n",
        "  Além disso, após os testes podemos criar o melhor pipeline, treina-lo, testa-lo e salva-lo em um aquivo\n",
        "  ________________________________________________________________________________________________________________\n",
        "  PARAMETROS\n",
        "  ----------\n",
        "  modelo: modelo de classificação do sklearn\n",
        "      modelo que será utilizado nos testes do pipeline e de seus paramêtros, bem como no pipeline final\n",
        "  ________________________________________________________________________________________________________________\n",
        "  ATRIBUTOS\n",
        "  ---------\n",
        "  metrica: str\n",
        "      metrica utilizada nos cálculos comparativos dos testes, definida no método testa_parametros()\n",
        "  \n",
        "  Xs: dict\n",
        "      dicionários dos Xs testados com base nas bases envidas no método testa_parametros()\n",
        "\n",
        "  ys: dict\n",
        "      dicionários dos ys testados com base nas bases envidas no método testa_parametros()\n",
        "\n",
        "  resultados: DataFrame\n",
        "      DataFrame com os resultados do método testa_parametro(), tem os resultados e as etapas do pipeline utilizado\n",
        "\n",
        "  indice: int\n",
        "      indice da linha dos resultados que iremos utilizar para criar o pipeline final, criado no método cria_pipeline()\n",
        "\n",
        "  pipe: Pipeline\n",
        "      pipeline final criado no método cria_pipeline()\n",
        "\n",
        "  base: str\n",
        "      Nome da base que teve o melhor resultado, para utilização na avaliação das métricas do pipeline final.\n",
        "      Criada no método cria_pipeline()\n",
        "  \n",
        "  modelo_final: Pipeline\n",
        "      modelo do pipeline utilizado para ser salvo no arquivo. \n",
        "      Criado no método cria_modelo_final() ou cria_salva_modelo_final()\n",
        "  \"\"\"\n",
        "  def __init__( self, modelo):\n",
        "    self.modelo = modelo\n",
        "\n",
        "  def testa_parametros(self, parametros, lista_dados, lista_reescalas=['nenhuma'], \n",
        "                      selecao_menor=-30, selecao_maior=30, passo=30, n_splits = 5, n_repeats=10, metrica='roc_auc'):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    testa deiveros parametros, seleções e reescalas conforme solicitação do usuário\n",
        "\n",
        "    por padrão todas os testes colocam no lógica do pipeline um objeto da classe remove_corr(), devido a testes\n",
        "    anteriores demonstrarem a eficácia da utilização desta seleção prévia\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADAS\n",
        "    --------\n",
        "    parametros: dict\n",
        "        dicionário com os parametros do modelo que queremos testar. lembrando que o formato de cada item é o nome \n",
        "        parametro e a lista de valores que se deseja testar\n",
        "\n",
        "    lista_dados: list de tuplas\n",
        "        lista contendo tuplas com a base que queremos testar (DataFrame) e nome que iremos identifica-la (str)\n",
        "        Exemplo: [(dados_LE,'LE'),(dados_OHE,'OHE')]\n",
        "    \n",
        "    lista_reescalas: list\n",
        "        lista deve conter as funções de reescala que queremos utilizar ou a string 'nenhuma'\n",
        "    \n",
        "    selecao_menor: int\n",
        "        valor do percentual (será divido por 100) que queremos distanciar da média no paramêtro threshold da função\n",
        "        SelectFromModel. Este é o valor inferior do range que será testado.\n",
        "        Os valores menores ou iguais a -100 do range farão com que não se aplique essa segunda seleção no número\n",
        "    \n",
        "    selecao_maior: int\n",
        "        valor do percentual (será divido por 100) que queremos distanciar da média no paramêtro threshold da função\n",
        "        SelectFromModel. Este é o valor superio do range que será testado.\n",
        "        Os valores menores ou iguais a -100 do range farão com que não se aplique essa segunda seleção no número\n",
        "\n",
        "    passo: int\n",
        "        valor do aumento gradual que será colocado na selecao_menor até chegar na selecao_maior dentro do range.\n",
        "    \n",
        "    n_splits: int\n",
        "        número de divisões que será realizada no objeto RepeatedStratifiedKFold durante os testes\n",
        "\n",
        "    n_repeats: int\n",
        "        número de repetições que será realizada no objeto RepeatedStratifiedKFold durante os testes\n",
        "    \n",
        "    metrica: str\n",
        "        metrica utilizada nos cálculos comparativos dos testes\n",
        "    ________________________________________________________________________________________________________________\n",
        "    SAIDA\n",
        "    -----\n",
        "    DataFrame\n",
        "        Os resultados tratados já selecionando os 5 melhores, do pior para o melhor, utilizando como métrica o \n",
        "        valor do limite inferior do intervalo de confiança de 95%\n",
        "    \"\"\"\n",
        "    self.metrica = metrica  \n",
        "    cv = RepeatedStratifiedKFold(n_splits = n_splits, n_repeats = n_repeats)\n",
        "    grid = GridSearchCV(self.modelo,parametros, scoring=metrica,cv=cv)\n",
        "    melhores = {'base':[],'reescala':[],'selecionador':[],'modelo':[],'parametros':[],self.metrica:[],'desvio_padrao':[]}\n",
        "    self.Xs = {}\n",
        "    self.ys = {}\n",
        "    for dados, base in lista_dados:\n",
        "      dados = dados.sample(frac=1).reset_index(drop=True)\n",
        "      y = dados[\"ICU\"]\n",
        "      X = dados.drop([\"ICU\",\"WINDOW\",\"PATIENT_VISIT_IDENTIFIER\"], axis=1)\n",
        "      self.Xs = {base: X}\n",
        "      self.ys = {base: y}\n",
        "      _ = remove_corr().fit(X,y)\n",
        "      X = _.transform(X)\n",
        "      modelo_ = self.modelo.fit(X,y)\n",
        "      for i in range(selecao_menor,selecao_maior+1,passo):\n",
        "        if i > -100:\n",
        "          threshold_i = str(1+i/100)+'*mean'\n",
        "          seletor = SelectFromModel(modelo_, threshold=threshold_i).fit(X,y)\n",
        "          X_selecionado = seletor.transform(X)\n",
        "        else:\n",
        "          threshold_i = 'sem seleção adicional'\n",
        "          seletor = {'threshold':threshold_i,'colunas':X.columns}\n",
        "          X_selecionado = X.copy()\n",
        "        for item in lista_reescalas:\n",
        "          if item != 'nenhuma':\n",
        "            X_revisto = item.fit_transform(X_selecionado)\n",
        "          else:\n",
        "            X_revisto = X_selecionado\n",
        "          resultados= grid.fit(X_revisto,y)\n",
        "          desvio = resultados.cv_results_['std_test_score'][resultados.best_index_]\n",
        "          melhores['base'].append(base)\n",
        "          melhores['reescala'].append(item)\n",
        "          melhores['selecionador'].append(seletor)\n",
        "          melhores['modelo'].append(resultados)\n",
        "          melhores['parametros'].append(resultados.best_params_)\n",
        "          melhores[self.metrica].append(resultados.best_score_)\n",
        "          melhores['desvio_padrao'].append(desvio)\n",
        "          print(f'Finalizada iteração: seleção - {threshold_i}, reescala - {item}, base - {base}')\n",
        "\n",
        "    self.resultados = pd.DataFrame(melhores)\n",
        "    return self.classifica_resultados().tail()\n",
        "\n",
        "  def classifica_resultados(self, ordenar='inferior'): \n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ajusta os resultados num formato mais amigável e já ordena o campo informado, do menor para o maior\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADA\n",
        "    -------\n",
        "    ordenar: str\n",
        "        campo que desejamos ordenar no fim do tratamento\n",
        "    ________________________________________________________________________________________________________________\n",
        "    SAIDA\n",
        "    -----\n",
        "    DataFrame\n",
        "        Os resultados tratados ordenados pelo campo definido em ordenar, do menor para o maior\n",
        "    \"\"\"\n",
        "    r = self.resultados.copy()\n",
        "    r['inferior']=r[self.metrica]-2*r['desvio_padrao']\n",
        "    r['superior']=r[self.metrica]+2*r['desvio_padrao']\n",
        "    colunas = r.columns.tolist()\n",
        "    colunas = colunas[2:]+colunas[:2]\n",
        "    r = r[colunas]\n",
        "    r['threshold']=\"\"\n",
        "    r['qtd_variaveis']=\"\"\n",
        "    for i in r.index.values:\n",
        "      if type(r.loc[i,'selecionador']) == dict:\n",
        "        r.loc[i,'threshold'] = r.loc[i,'selecionador']['threshold']\n",
        "        r.loc[i,'qtd_variaveis'] = len(r.loc[i,'selecionador']['colunas'])\n",
        "      else:\n",
        "        r.loc[i,'threshold'] = r.loc[i,'selecionador'].threshold\n",
        "        r.loc[i,'qtd_variaveis'] = len(r.loc[i,'selecionador'].get_feature_names_out())\n",
        "    for titulo in r.loc[0,'parametros'].keys():\n",
        "      r[titulo]=''\n",
        "      for i in r.index.values:\n",
        "        r.loc[i,titulo] = r.loc[i,'parametros'][titulo]\n",
        "    r.drop(['selecionador','modelo','parametros'], axis=1, inplace=True)\n",
        "    return r.sort_values(ordenar)\n",
        "\n",
        "  def cria_pipeline(self, indice=None):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    cria um pipeline com base nos resultados obtidos que fica salvo no atributo 'pipe'\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADA\n",
        "    -------\n",
        "    indice: str\n",
        "        indice da base de resultados que queremos utilizar na criação do pipeline. Se não for passado irá\n",
        "        utilizar o indice do maior limite inferior do intervalor de confiança de 95%.\n",
        "    \"\"\"\n",
        "    pipe = [('seletor1',remove_corr())]\n",
        "    \n",
        "    if indice:\n",
        "      self.indice = indice\n",
        "    else:\n",
        "      _ = self.classifica_resultados().reset_index().iloc[-1]\n",
        "      self.indice = _['index']\n",
        "    \n",
        "    if type(self.resultados.loc[self.indice,'selecionador']) != dict:\n",
        "      pipe.append(('seletor2',self.resultados.loc[self.indice,'selecionador']))\n",
        "    if self.resultados.loc[self.indice,'reescala'] != 'nenhuma':\n",
        "      pipe.append(('reescala',self.resultados.loc[self.indice,'reescala']))\n",
        "    pipe.append(('modelo',self.resultados.loc[self.indice,'modelo'].best_estimator_))\n",
        "    self.pipe = Pipeline(pipe)\n",
        "    self.base = self.resultados.loc[self.indice,'base']\n",
        "    return None\n",
        "\n",
        "  def roda_pipeline_metricas(self, random_state=None):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    com base no pipeline criado, plota a matriz de confusão, os reportes de classificação e o ROC AUC com base\n",
        "    em um split entre treino e dados aleatório da base definida como melhor \n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADA\n",
        "    -------\n",
        "    random_state: int\n",
        "        caso se queira definir uma semente para que se tenha o mesmo resultado ao se rodar novamente este método\n",
        "    \"\"\"\n",
        "    X_treino, X_teste, y_treino, y_teste = train_test_split(self.Xs[self.base], self.ys[self.base], \n",
        "                                                            stratify=self.ys[self.base], random_state=random_state)\n",
        "    self.pipe.fit(X_treino, y_treino)\n",
        "\n",
        "    ConfusionMatrixDisplay.from_predictions(y_teste, self.pipe.predict(X_teste))\n",
        "    plt.show()\n",
        "    print('\\n', classification_report(y_teste, self.pipe.predict(X_teste)))\n",
        "    print(f'ROC AUC: {roc_auc_score(y_teste, self.pipe.predict_proba(X_teste)[:,1]):.2%}')\n",
        "    \n",
        "    return None\n",
        " \n",
        "  def cria_modelo_final(self):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    salva o pipeline numa atibuto modelo_final que pode ser preservado para outras comparações ou ser salvo em um \n",
        "    arquivo\n",
        "    \"\"\"\n",
        "    self.modelo_final = self.pipe.fit(self.Xs[self.base], self.ys[self.base])\n",
        "    return self.modelo_final\n",
        "\n",
        "  def salva_modelo_final(self, nome_arquivo='modelo_final.joblib'):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    salva o modelo final em um arquivo joblib para utilização posterior ou para utilização na produção\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADA\n",
        "    --------\n",
        "    nome_arquivo: str\n",
        "        nome do arquivo onde ficará salvo o modelo\n",
        "    ________________________________________________________________________________________________________________\n",
        "    SAIDA\n",
        "    -----\n",
        "    str\n",
        "        informa que o modelo foi salvo e o nome do arquivo\n",
        "    \"\"\"\n",
        "    dump(self.modelo_final, nome_arquivo)\n",
        "    return 'modelo salvo como: ' + nome_arquivo\n",
        "\n",
        "  def cria_salva_modelo_final(self, nome_arquivo='modelo_final.joblib'):\n",
        "    \"\"\"\n",
        "    ________________________________________________________________________________________________________________\n",
        "    salva o pipeline numa atibuto modelo_final que pode ser preservado para outras comparações. Também salva o \n",
        "    modelo final em um arquivo joblib para utilização posterior ou para utilização na produção\n",
        "    ________________________________________________________________________________________________________________\n",
        "    ENTRADA\n",
        "    --------\n",
        "    nome_arquivo: str\n",
        "        nome do arquivo onde ficará salvo o modelo\n",
        "    ________________________________________________________________________________________________________________\n",
        "    SAIDA\n",
        "    -----\n",
        "    str\n",
        "        informa que o modelo foi salvo e o nome do arquivo\n",
        "    \"\"\"\n",
        "    self.modelo_final = self.pipe.fit(self.Xs[self.base], self.ys[self.base])\n",
        "    dump(self.modelo_final, nome_arquivo)\n",
        "    return 'modelo salvo como: ' + nome_arquivo"
      ],
      "metadata": {
        "id": "n2BYh0SJHXaB"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}